# capstone-fall-2024
Classifying Film Scripts into Acclaimed vs. Panned Film Scripts using BERT (Capstone)


Abstract
This capstone project explores the linguistic implications and patterns observed in a corpus of film scripts.  The dataset used was a corpus of screenplays (in the form of written text). Google’s BERT (Bidirectional encoder representations from transformers) were used as a text classifier for the project.  The project explores the idea that BERT can be trained to classify screenplays as acclaimed versus panned after receiving manually labeled data.  BERT was used because of its well-documented impressive performance with classifying text after being fine-tuned.  However, an interesting problem arose–BERT has a token limit for optimal performance.  The large language model is suited to handle a maximum of 512 tokens for training.  As expected, the screenplays used for this project had a much higher token count on average–about 34,000 tokens per screenplay before any preprocessing.  In an effort to combat the size discrepancy, chunking and overlapping chunking text preprocessing techniques were employed.  After those processes were performed, the model was fed the binary labeled data.  The screenplays that received prestigious award nominations from the Academy of Motion Picture Arts and Sciences (AMPAS) were given the label of 1 (acclaimed).  The screenplays that received negative attention from the satirical Golden Raspberry Awards were labeled 0 (panned).  The aim of this project was to highlight the path to an award-winning screenplay.  The project focuses on the following: combating BERT’s token size limitation, BERT’s performance after being fine-tuned for a text classification task related to the project’s subject, and what potential linguistic analyses can be performed on the data.  The numbers point to the idea that overlapping chunking would be the preferred method to begin to tackle the token size dilemma presented in the project.
